{
    "docs": [
        {
            "location": "/", 
            "text": "OnlineStats.jl\n\n\nOnlineStats\n is a Julia package which provides online algorithms for statistical models.\n\n\nOnline algorithms are well suited for streaming data or when data is too large to hold in memory.\n\n\nObservations are processed one at a time and all \nalgorithms use O(1) memory\n.\n\n\n\n\nOverview\n\n\nEvery OnlineStat is a Type\n\n\nusing\n \nOnlineStats\n\n\no\n \n=\n \nMean\n()\n\n\n\n\n\n\nAll OnlineStats can be updated\n\n\ny\n \n=\n \nrandn\n(\n100\n)\n\n\n\nfor\n \nyi\n \nin\n \ny\n\n    \nfit!\n(\no\n,\n \nyi\n)\n\n\nend\n\n\n\n# or more simply:\n\n\nfit!\n(\no\n,\n \ny\n)\n\n\n\n\n\n\nOnlineStats share a common interface\n\n\nvalue\n(\no\n)\n  \n# associated value of an OnlineStat\n\n\nnobs\n(\no\n)\n   \n# number of observations used\n\n\n\n\n\n\n\n\nWhat Can OnlineStats Do?\n\n\nWhile many estimates can be calculated analytically with an online algorithm, several\ntype rely on stochastic approximation.\n\n\nSummary Statistics\n\n\n\n\nMean: \nMean\n, \nMeans\n\n\nVariance: \nVariance\n, \nVariances\n\n\nQuantiles: \nQuantileMM\n, \nQuantileSGD\n\n\nCovariance Matrix: \nCovMatrix\n\n\nMaximum and Minimum:  \nExtrema\n\n\nSkewness and Kurtosis:  \nMoments\n\n\nSum/Differences:  \nSum\n, \nSums\n, \nDiff\n, \nDiffs\n\n\n\n\nDensity Estimation\n\n\n\n\ndistributionfit(D, data)\n\n\nFor \nD in [Beta, Categorical, Cauchy, Gamma, LogNormal, Normal, Multinomial, MvNormal]\n\n\n\n\n\n\nGaussian Mixtures: \nNormalMix\n\n\n\n\nPredictive Modeling\n\n\n\n\nSee OnlineStatsModels.jl\n\n\n\n\nOther\n\n\n\n\nK-Means clustering: \nKMeans\n\n\nBootstrapping: \nBernoulliBootstrap\n, \nPoissonBootstrap\n\n\nApproximate count of distinct elements: \nHyperLogLog", 
            "title": "Home"
        }, 
        {
            "location": "/#onlinestatsjl", 
            "text": "OnlineStats  is a Julia package which provides online algorithms for statistical models.  Online algorithms are well suited for streaming data or when data is too large to hold in memory.  Observations are processed one at a time and all  algorithms use O(1) memory .", 
            "title": "OnlineStats.jl"
        }, 
        {
            "location": "/#overview", 
            "text": "", 
            "title": "Overview"
        }, 
        {
            "location": "/#every-onlinestat-is-a-type", 
            "text": "using   OnlineStats  o   =   Mean ()", 
            "title": "Every OnlineStat is a Type"
        }, 
        {
            "location": "/#all-onlinestats-can-be-updated", 
            "text": "y   =   randn ( 100 )  for   yi   in   y \n     fit! ( o ,   yi )  end  # or more simply:  fit! ( o ,   y )", 
            "title": "All OnlineStats can be updated"
        }, 
        {
            "location": "/#onlinestats-share-a-common-interface", 
            "text": "value ( o )    # associated value of an OnlineStat  nobs ( o )     # number of observations used", 
            "title": "OnlineStats share a common interface"
        }, 
        {
            "location": "/#what-can-onlinestats-do", 
            "text": "While many estimates can be calculated analytically with an online algorithm, several\ntype rely on stochastic approximation.", 
            "title": "What Can OnlineStats Do?"
        }, 
        {
            "location": "/#summary-statistics", 
            "text": "Mean:  Mean ,  Means  Variance:  Variance ,  Variances  Quantiles:  QuantileMM ,  QuantileSGD  Covariance Matrix:  CovMatrix  Maximum and Minimum:   Extrema  Skewness and Kurtosis:   Moments  Sum/Differences:   Sum ,  Sums ,  Diff ,  Diffs", 
            "title": "Summary Statistics"
        }, 
        {
            "location": "/#density-estimation", 
            "text": "distributionfit(D, data)  For  D in [Beta, Categorical, Cauchy, Gamma, LogNormal, Normal, Multinomial, MvNormal]    Gaussian Mixtures:  NormalMix", 
            "title": "Density Estimation"
        }, 
        {
            "location": "/#predictive-modeling", 
            "text": "See OnlineStatsModels.jl", 
            "title": "Predictive Modeling"
        }, 
        {
            "location": "/#other", 
            "text": "K-Means clustering:  KMeans  Bootstrapping:  BernoulliBootstrap ,  PoissonBootstrap  Approximate count of distinct elements:  HyperLogLog", 
            "title": "Other"
        }, 
        {
            "location": "/weight/", 
            "text": "Weighting\n\n\nOnlineStats are parameterized by a \nWeight\n type that determines the influence of the\nnext observation.  The \nWeight\n is always the last argument of the constructor.\n\n\n\n\nWeight Types\n\n\nMany updates take the form of a weighted average.  For a current estimate \n\\theta^{(t-1)}\n and new value \nx_t\n, we update the estimate with:\n\n\n\n\n\\theta^{(t)} = (1 - \\gamma_t) \\theta^{(t-1)} + \\gamma_t \\; x_t\n\n\n\n\nConsider how the weights \n\\gamma_t\n affect the influence of the new value on the estimate.  The weight types below will be explained in terms of the weights \n\\gamma_t\n.\n\n\nEqualWeight\n\n\nEqualWeight()\n\n\n\n\n\nMany online algorithms produce the same results as offline counterparts when using \nEqualWeight\n.  Each observation contributes equally.  This is the most common default.\n\n\n\n\n\\gamma_t = \\frac{1}{t}\n\n\n\n\nExponentialWeight\n\n\nExponentialWeight(\u03bb::Float64)\nExponentialWeight(lookback::Int)\n\n\n\n\n\nThe update weight is constant, so newer observations have higher influence.\n\n\n\n\n\\gamma_t = \\lambda\n\n\n\n\nwhere \n\u03bb = 2 / (lookback + 1)\n\n\nBoundedEqualWeight\n\n\nBoundedEqualWeight(\u03bb::Float64)\nBoundedEqualWeight(lookback::Int)\n\n\n\n\n\nUse \nEqualWeight\n until a minimum weight is reached, then uses \nExponentialWeight\n\n\n\n\n\\gamma_t = \\text{max}\\left(\\lambda, \\frac{1}{t}\\right)\n\n\n\n\nLearningRate\n\n\nLearningRate(r::Float64 = .5, \u03bb::Float64 = 0.0)\n\n\n\n\n\nMainly for algorithms using stochastic approximation.  The weights decrease at a \"slow\" rate\nuntil reaching a minimum weight, then uses \nExponentialWeight\n.\n\n\n\n\n\\gamma_t = \\text{max}\\left(\\lambda, \\frac{1}{t^r}\\right), \\quad r \\in [.5, 1]\n\n\n\n\nOverride the Weight\n\n\nYou can override an OnlineStat's Weight with an additional argument to \nfit!\n.  \n\n\ny\n \n=\n \nrandn\n(\n1000\n)\n\n\no\n \n=\n \nMean\n(\nEqualWeight\n())\n\n\nfit!\n(\no\n,\n \ny\n,\n \n.\n01\n)\n  \n# use weight of .01 for each observation\n\n\n\nwts\n \n=\n \nrand\n(\n1000\n)\n\n\nfit!\n(\no\n,\n \ny\n,\n \nwts\n)\n  \n# use weight of wts[i] for observation y[i]", 
            "title": "Weighting"
        }, 
        {
            "location": "/weight/#weighting", 
            "text": "OnlineStats are parameterized by a  Weight  type that determines the influence of the\nnext observation.  The  Weight  is always the last argument of the constructor.", 
            "title": "Weighting"
        }, 
        {
            "location": "/weight/#weight-types", 
            "text": "Many updates take the form of a weighted average.  For a current estimate  \\theta^{(t-1)}  and new value  x_t , we update the estimate with:   \\theta^{(t)} = (1 - \\gamma_t) \\theta^{(t-1)} + \\gamma_t \\; x_t   Consider how the weights  \\gamma_t  affect the influence of the new value on the estimate.  The weight types below will be explained in terms of the weights  \\gamma_t .", 
            "title": "Weight Types"
        }, 
        {
            "location": "/weight/#equalweight", 
            "text": "EqualWeight()  Many online algorithms produce the same results as offline counterparts when using  EqualWeight .  Each observation contributes equally.  This is the most common default.   \\gamma_t = \\frac{1}{t}", 
            "title": "EqualWeight"
        }, 
        {
            "location": "/weight/#exponentialweight", 
            "text": "ExponentialWeight(\u03bb::Float64)\nExponentialWeight(lookback::Int)  The update weight is constant, so newer observations have higher influence.   \\gamma_t = \\lambda   where  \u03bb = 2 / (lookback + 1)", 
            "title": "ExponentialWeight"
        }, 
        {
            "location": "/weight/#boundedequalweight", 
            "text": "BoundedEqualWeight(\u03bb::Float64)\nBoundedEqualWeight(lookback::Int)  Use  EqualWeight  until a minimum weight is reached, then uses  ExponentialWeight   \\gamma_t = \\text{max}\\left(\\lambda, \\frac{1}{t}\\right)", 
            "title": "BoundedEqualWeight"
        }, 
        {
            "location": "/weight/#learningrate", 
            "text": "LearningRate(r::Float64 = .5, \u03bb::Float64 = 0.0)  Mainly for algorithms using stochastic approximation.  The weights decrease at a \"slow\" rate\nuntil reaching a minimum weight, then uses  ExponentialWeight .   \\gamma_t = \\text{max}\\left(\\lambda, \\frac{1}{t^r}\\right), \\quad r \\in [.5, 1]", 
            "title": "LearningRate"
        }, 
        {
            "location": "/weight/#override-the-weight", 
            "text": "You can override an OnlineStat's Weight with an additional argument to  fit! .    y   =   randn ( 1000 )  o   =   Mean ( EqualWeight ())  fit! ( o ,   y ,   . 01 )    # use weight of .01 for each observation  wts   =   rand ( 1000 )  fit! ( o ,   y ,   wts )    # use weight of wts[i] for observation y[i]", 
            "title": "Override the Weight"
        }, 
        {
            "location": "/callback/", 
            "text": "Callbacks\n\n\nWhile an OnlineStat is being updated, you may wish to perform an action like print intermediate results to a log file or update a plot.  For this purpose, OnlineStats exports a \nmaprows\n function.\n\n\nmaprows(f::Function, b::Integer, data...)\n\n\nmaprows\n works similar to \nBase.mapslices\n, but maps \nb\n rows at a time.  It is best used with Julia's do block syntax.\n\n\nExample 1\n\n\nInput\n\n\ny\n \n=\n \nrandn\n(\n100\n)\n\n\no\n \n=\n \nMean\n()\n\n\nmaprows\n(\n20\n,\n \ny\n)\n \ndo\n \nyi\n\n    \nfit!\n(\no\n,\n \nyi\n)\n\n    \ninfo\n(\nvalue of mean is \n$(mean(o))\n)\n\n\nend\n\n\n\n\n\n\nOutput\n\n\nINFO\n:\n \nvalue\n \nof\n \nmean\n \nis\n \n0.06340121912925167\n\n\nINFO\n:\n \nvalue\n \nof\n \nmean\n \nis\n \n-\n0.06576995293439102\n\n\nINFO\n:\n \nvalue\n \nof\n \nmean\n \nis\n \n0.05374292238752276\n\n\nINFO\n:\n \nvalue\n \nof\n \nmean\n \nis\n \n0.008857939006120167\n\n\nINFO\n:\n \nvalue\n \nof\n \nmean\n \nis\n \n0.016199508928045905\n\n\n\n\n\n\nExample 2\n\n\nInput\n\n\nusing\n \nPlots\n;\n \npyplot\n()\n\n\ny\n \n=\n \nrandn\n(\n10_000\n)\n\n\n\no\n \n=\n \nQuantileMM\n(\nLearningRate\n(\n.\n7\n),\n \ntau\n \n=\n \n[\n.\n25\n,\n \n.\n5\n,\n \n.\n75\n])\n\n\n\nplt\n \n=\n \nplot\n(\nzeros\n(\n1\n,\n \n3\n),\n \nzeros\n(\n1\n,\n \n3\n))\n       \n# initialize plot\n\n\n\nmaprows\n(\n50\n,\n \ny\n)\n \ndo\n \nyi\n              \n# for each batch of 50 observations\n\n    \nfit!\n(\no\n,\n \nyi\n,\n \n5\n)\n                 \n# fit in minibatches of 5\n\n    \npush!\n(\nplt\n,\n \nnobs\n(\no\n),\n \nvalue\n(\no\n))\n  \n# Add a value to the plot\n\n\nend\n\n\n\ndisplay\n(\nplt\n)\n\n\n\n\n\n\nOutput", 
            "title": "Callbacks"
        }, 
        {
            "location": "/callback/#callbacks", 
            "text": "While an OnlineStat is being updated, you may wish to perform an action like print intermediate results to a log file or update a plot.  For this purpose, OnlineStats exports a  maprows  function.  maprows(f::Function, b::Integer, data...)  maprows  works similar to  Base.mapslices , but maps  b  rows at a time.  It is best used with Julia's do block syntax.", 
            "title": "Callbacks"
        }, 
        {
            "location": "/callback/#example-1", 
            "text": "", 
            "title": "Example 1"
        }, 
        {
            "location": "/callback/#input", 
            "text": "y   =   randn ( 100 )  o   =   Mean ()  maprows ( 20 ,   y )   do   yi \n     fit! ( o ,   yi ) \n     info ( value of mean is  $(mean(o)) )  end", 
            "title": "Input"
        }, 
        {
            "location": "/callback/#output", 
            "text": "INFO :   value   of   mean   is   0.06340121912925167  INFO :   value   of   mean   is   - 0.06576995293439102  INFO :   value   of   mean   is   0.05374292238752276  INFO :   value   of   mean   is   0.008857939006120167  INFO :   value   of   mean   is   0.016199508928045905", 
            "title": "Output"
        }, 
        {
            "location": "/callback/#example-2", 
            "text": "", 
            "title": "Example 2"
        }, 
        {
            "location": "/callback/#input_1", 
            "text": "using   Plots ;   pyplot ()  y   =   randn ( 10_000 )  o   =   QuantileMM ( LearningRate ( . 7 ),   tau   =   [ . 25 ,   . 5 ,   . 75 ])  plt   =   plot ( zeros ( 1 ,   3 ),   zeros ( 1 ,   3 ))         # initialize plot  maprows ( 50 ,   y )   do   yi                # for each batch of 50 observations \n     fit! ( o ,   yi ,   5 )                   # fit in minibatches of 5 \n     push! ( plt ,   nobs ( o ),   value ( o ))    # Add a value to the plot  end  display ( plt )", 
            "title": "Input"
        }, 
        {
            "location": "/callback/#output_1", 
            "text": "", 
            "title": "Output"
        }, 
        {
            "location": "/merging/", 
            "text": "Merging OnlineStats\n\n\nSome OnlineStat objects can be merged together.  The syntax for in-place merging is\n\n\nmerge!\n(\no1\n,\n \no2\n,\n \narg\n)\n\n\n\n\n\n\nWhere \no1\n/\no2\n are OnlineStats of the same type and \narg\n is used to determine how the value(s) from \no2\n should be merged into \no1\n.\n\n\ny1\n \n=\n \nrandn\n(\n100\n)\n\n\ny2\n \n=\n \nrandn\n(\n100\n)\n\n\n\no1\n \n=\n \nMean\n(\ny1\n)\n\n\no2\n \n=\n \nMean\n(\ny2\n)\n\n\n\n# Treat o2 as a new batch of data.  Essentially:\n\n\n# o1 = Mean(y1); fit!(o1, y2)\n\n\nmerge!\n(\no1\n,\n \no2\n,\n \n:\nappend\n)\n\n\n\n# Use weighted average based on nobs of each OnlineStat\n\n\nmerge!\n(\no1\n,\n \no2\n,\n \n:\nmean\n)\n\n\n\n# Treat o2 as a single observation.  Essentially:\n\n\n# o1 = Mean(y1); fit!(o1, mean(y2))\n\n\nmerge!\n(\no1\n,\n \no2\n,\n \n:\nsingleton\n)\n\n\n\n# Provide the ratio of influence o2 should have.\n\n\nw\n \n=\n \n.\n5\n\n\nmerge!\n(\no1\n,\n \no2\n,\n \nw\n)", 
            "title": "Merging"
        }, 
        {
            "location": "/merging/#merging-onlinestats", 
            "text": "Some OnlineStat objects can be merged together.  The syntax for in-place merging is  merge! ( o1 ,   o2 ,   arg )   Where  o1 / o2  are OnlineStats of the same type and  arg  is used to determine how the value(s) from  o2  should be merged into  o1 .  y1   =   randn ( 100 )  y2   =   randn ( 100 )  o1   =   Mean ( y1 )  o2   =   Mean ( y2 )  # Treat o2 as a new batch of data.  Essentially:  # o1 = Mean(y1); fit!(o1, y2)  merge! ( o1 ,   o2 ,   : append )  # Use weighted average based on nobs of each OnlineStat  merge! ( o1 ,   o2 ,   : mean )  # Treat o2 as a single observation.  Essentially:  # o1 = Mean(y1); fit!(o1, mean(y2))  merge! ( o1 ,   o2 ,   : singleton )  # Provide the ratio of influence o2 should have.  w   =   . 5  merge! ( o1 ,   o2 ,   w )", 
            "title": "Merging OnlineStats"
        }, 
        {
            "location": "/api/", 
            "text": "API\n\n\nBernoulliBootstrap\n\n\nBernoulliBootstrap(o::OnlineStat, f::Function, r::Int = 1000)\n\n\nCreate a double-or-nothing bootstrap using \nr\n replicates of \no\n for estimate \nf(o)\n\n\nExample:\n\n\nBernoulliBootstrap\n(\nMean\n(),\n \nmean\n,\n \n1000\n)\n\n\n\n\n\n\nBiasMatrix\n\n\nAdda bias/intercept term to a matrix on the fly without creating or copying data:\n\n\n\n\nBiasMatrix(rand(10,5))\n is roughly equivalent to \nhcat(rand(10,5), ones(10))\n\n\n\n\nBiasVector\n\n\nAdd a bias/intercept term to a vector on the fly without creating or copying data:\n\n\n\n\nBiasVector(rand(10))\n is roughly equivalent to \nvcat(rand(10), 1.0)\n\n\n\n\nBoundedEqualWeight\n\n\nOne of the \nWeight\n types.  Uses \nEqualWeight\n until reaching \n\u03bb = 2 / (1 + lookback)\n, then weights are held constant.\n\n\n\n\nBoundedEqualWeight(\u03bb::Float64)\n\n\nBoundedEqualWeight(lookback::Int)\n\n\n\n\nCovMatrix\n\n\nCovariance matrix, similar to \ncov(x)\n.\n\n\no\n \n=\n \nCovMatrix\n(\nx\n,\n \nEqualWeight\n())\n\n\no\n \n=\n \nCovMatrix\n(\nx\n)\n\n\nfit!\n(\no\n,\n \nx2\n)\n\n\n\ncor\n(\no\n)\n\n\ncov\n(\no\n)\n\n\nmean\n(\no\n)\n\n\nvar\n(\no\n)\n\n\n\n\n\n\nDiff\n\n\nTrack the last value and the last difference.\n\n\no\n \n=\n \nDiff\n()\n\n\no\n \n=\n \nDiff\n(\ny\n)\n\n\n\n\n\n\nDiffs\n\n\nTrack the last value and the last difference for multiple series.  Ignores \nWeight\n.\n\n\no\n \n=\n \nDiffs\n()\n\n\no\n \n=\n \nDiffs\n(\ny\n)\n\n\n\n\n\n\nEqualWeight\n\n\nOne of the \nWeight\n types.  Observations are weighted equally.  For analytical updates, the online algorithm will give results equal to the offline version.\n\n\n\n\nEqualWeight()\n\n\n\n\nExponentialWeight\n\n\nOne of the \nWeight\n types.  Updates are performed with a constant weight \n\u03bb = 2 / (1 + lookback)\n.\n\n\n\n\nExponentialWeight(\u03bb::Float64)\n\n\nExponentialWeight(lookback::Int)\n\n\n\n\nExtrema\n\n\nExtrema (maximum and minimum).\n\n\no\n \n=\n \nExtrema\n(\ny\n)\n\n\nfit!\n(\no\n,\n \ny2\n)\n\n\nextrema\n(\no\n)\n\n\n\n\n\n\nFitBeta\n\n\nNo documentation found.\n\n\nSummary:\n\n\ntype OnlineStats.FitBeta{W\n:OnlineStats.Weight} \n: OnlineStats.DistributionStat{OnlineStats.ScalarInput}\n\n\n\n\n\nFields:\n\n\nvalue :: Distributions.Beta{T\n:Real}\nvar   :: OnlineStats.Variance{W\n:OnlineStats.Weight}\n\n\n\n\n\nFitCategorical\n\n\nFind the proportions for each unique input.  Categories are sorted by proportions. Ignores \nWeight\n.\n\n\no\n \n=\n \nFitCategorical\n(\ny\n)\n\n\n\n\n\n\nFitCauchy\n\n\nNo documentation found.\n\n\nSummary:\n\n\ntype OnlineStats.FitCauchy{W\n:OnlineStats.Weight} \n: OnlineStats.DistributionStat{OnlineStats.ScalarInput}\n\n\n\n\n\nFields:\n\n\nvalue :: Distributions.Cauchy{T\n:Real}\nq     :: OnlineStats.QuantileMM{W\n:OnlineStats.Weight}\n\n\n\n\n\nFitGamma\n\n\nNo documentation found.\n\n\nSummary:\n\n\ntype OnlineStats.FitGamma{W\n:OnlineStats.Weight} \n: OnlineStats.DistributionStat{OnlineStats.ScalarInput}\n\n\n\n\n\nFields:\n\n\nvalue :: Distributions.Gamma{T\n:Real}\nvar   :: OnlineStats.Variance{W\n:OnlineStats.Weight}\n\n\n\n\n\nFitLogNormal\n\n\nNo documentation found.\n\n\nSummary:\n\n\ntype OnlineStats.FitLogNormal{W\n:OnlineStats.Weight} \n: OnlineStats.DistributionStat{OnlineStats.ScalarInput}\n\n\n\n\n\nFields:\n\n\nvalue :: Distributions.LogNormal{T\n:Real}\nvar   :: OnlineStats.Variance{W\n:OnlineStats.Weight}\n\n\n\n\n\nFitMultinomial\n\n\nNo documentation found.\n\n\nSummary:\n\n\ntype OnlineStats.FitMultinomial{W\n:OnlineStats.Weight} \n: OnlineStats.DistributionStat{OnlineStats.VectorInput}\n\n\n\n\n\nFields:\n\n\nvalue :: Distributions.Multinomial{T\n:Real}\nmeans :: OnlineStats.Means{W\n:OnlineStats.Weight}\n\n\n\n\n\nFitMvNormal\n\n\nNo documentation found.\n\n\nSummary:\n\n\ntype OnlineStats.FitMvNormal{W\n:OnlineStats.Weight} \n: OnlineStats.DistributionStat{OnlineStats.VectorInput}\n\n\n\n\n\nFields:\n\n\nvalue :: Distributions.MvNormal{T\n:Real,Cov\n:PDMats.AbstractPDMat,Mean\n:Union{Array{T,1},Distributions.ZeroVector}}\ncov   :: OnlineStats.CovMatrix{W\n:OnlineStats.Weight}\n\n\n\n\n\nFitNormal\n\n\nNo documentation found.\n\n\nSummary:\n\n\ntype OnlineStats.FitNormal{W\n:OnlineStats.Weight} \n: OnlineStats.DistributionStat{OnlineStats.ScalarInput}\n\n\n\n\n\nFields:\n\n\nvalue :: Distributions.Normal{T\n:Real}\nvar   :: OnlineStats.Variance{W\n:OnlineStats.Weight}\n\n\n\n\n\nFrozenBootstrap\n\n\nNo documentation found.\n\n\nSummary:\n\n\nimmutable OnlineStats.FrozenBootstrap \n: OnlineStats.Bootstrap{OnlineStats.ScalarInput}\n\n\n\n\n\nFields:\n\n\ncached_state :: Array{Float64,1}\nn            :: Int64\n\n\n\n\n\nHyperLogLog\n\n\nHyperLogLog(b)\n\n\nApproximate count of distinct elements.  \nHyperLogLog\n differs from other OnlineStats in that any input to \nfit!(o::HyperLogLog, input)\n is considered a singleton.  Thus, a vector of inputs must be done by:\n\n\no\n \n=\n \nHyperLogLog\n(\n4\n)\n\n\nfor\n \nyi\n \nin\n \ny\n\n    \nfit!\n(\no\n,\n \nyi\n)\n\n\nend\n\n\n\n\n\n\nKMeans\n\n\nApproximate K-Means clustering of multivariate data.\n\n\no\n \n=\n \nKMeans\n(\ny\n,\n \n3\n,\n \nLearningRate\n())\n\n\nvalue\n(\no\n)\n\n\n\n\n\n\nLearningRate\n\n\nOne of the \nWeight\n types.  It's primary use is for the OnlineStats that use stochastic approximation (\nStatLearn\n, \nQuantReg\n, \nQuantileMM\n, \nQuantileSGD\n, \nNormalMix\n, and \nKMeans\n).  The weight at update \nt\n is \n1 / t ^ r\n.  When weights reach \n\u03bb\n, they are held consant.  Compare to \nLearningRate2\n.\n\n\n\n\nLearningRate(r = 0.5, \u03bb = 0.0)\n\n\n\n\nLearningRate2\n\n\nOne of the \nWeight\n types.  It's primary use is for the OnlineStats that use stochastic approximation (\nStatLearn\n, \nQuantReg\n, \nQuantileMM\n, \nQuantileSGD\n, \nNormalMix\n, and \nKMeans\n).  The weight at update \nt\n is \n1 / (1 + c * (t - 1))\n.  When weights reach \n\u03bb\n, they are held consant.  Compare to \nLearningRate\n.\n\n\n\n\nLearningRate2(c = 0.5, \u03bb = 0.0)\n\n\n\n\nMean\n\n\nMean of a single series.\n\n\ny\n \n=\n \nrandn\n(\n100\n)\n\n\n\no\n \n=\n \nMean\n()\n\n\nfit!\n(\no\n,\n \ny\n)\n\n\n\no\n \n=\n \nMean\n(\ny\n)\n\n\n\n\n\n\nMeans\n\n\nMeans of multiple series, similar to \nmean(x, 1)\n.\n\n\nx\n \n=\n \nrandn\n(\n1000\n,\n \n5\n)\n\n\no\n \n=\n \nMeans\n(\n5\n)\n\n\nfit!\n(\no\n,\n \nx\n)\n\n\nmean\n(\no\n)\n\n\n\n\n\n\nMoments\n\n\nUnivariate, first four moments.  Provides \nmean\n, \nvar\n, \nskewness\n, \nkurtosis\n\n\no\n \n=\n \nMoments\n(\nx\n,\n \nEqualWeight\n())\n\n\no\n \n=\n \nMoments\n(\nx\n)\n\n\nfit!\n(\no\n,\n \nx2\n)\n\n\n\nmean\n(\no\n)\n\n\nvar\n(\no\n)\n\n\nstd\n(\no\n)\n\n\nStatsBase\n.\nskewness\n(\no\n)\n\n\nStatsBase\n.\nkurtosis\n(\no\n)\n\n\n\n\n\n\nNormalMix\n\n\nNormal Mixture of \nk\n components via an online EM algorithm.  \nstart\n is a keyword argument specifying the initial parameters.\n\n\no\n \n=\n \nNormalMix\n(\n2\n,\n \nLearningRate\n();\n \nstart\n \n=\n \nMixtureModel\n(\nNormal\n,\n \n[(\n0\n,\n \n1\n),\n \n(\n3\n,\n \n1\n)]))\n\n\nmean\n(\no\n)\n\n\nvar\n(\no\n)\n\n\nstd\n(\no\n)\n\n\n\n\n\n\nOnlineStat\n\n\nNo documentation found.\n\n\nSummary:\n\n\nabstract OnlineStats.OnlineStat{I\n:OnlineStats.Input} \n: Any\n\n\n\n\n\nSubtypes:\n\n\nOnlineStats.Bootstrap{I\n:OnlineStats.Input}\nOnlineStats.CovMatrix{W\n:OnlineStats.Weight}\nOnlineStats.Diffs{T\n:Real}\nOnlineStats.Diff{T\n:Real}\nOnlineStats.DistributionStat{I\n:OnlineStats.Input}\nOnlineStats.Extrema\nOnlineStats.HyperLogLog\nOnlineStats.KMeans{W\n:OnlineStats.Weight}\nOnlineStats.Means{W\n:OnlineStats.Weight}\nOnlineStats.Mean{W\n:OnlineStats.Weight}\nOnlineStats.Moments{W\n:OnlineStats.Weight}\nOnlineStats.OrderStatistics\nOnlineStats.QuantileMM{W\n:OnlineStats.Weight}\nOnlineStats.QuantileSGD{W\n:OnlineStats.StochasticWeight}\nOnlineStats.Sums{T\n:Real}\nOnlineStats.Sum{T\n:Real}\nOnlineStats.Variances{W\n:OnlineStats.Weight}\nOnlineStats.Variance{W\n:OnlineStats.Weight}\n\n\n\n\n\nPoissonBootstrap\n\n\nNo documentation found.\n\n\nOnlineStats.PoissonBootstrap\n is a \nFunction\n.\n\n\n# 4 methods for generic function \nPoissonBootstrap\n:\nPoissonBootstrap{T\n:OnlineStats.ScalarInput}(o::OnlineStats.OnlineStat{T}, f::Function) at /Users/joshday/.julia/v0.5/OnlineStats/src/streamstats/bootstrap.jl:63\nPoissonBootstrap{T\n:OnlineStats.ScalarInput}(o::OnlineStats.OnlineStat{T}, f::Function, r::Int64) at /Users/joshday/.julia/v0.5/OnlineStats/src/streamstats/bootstrap.jl:63\nPoissonBootstrap{T\n:OnlineStats.VectorInput}(o::OnlineStats.OnlineStat{T}, f::Function) at /Users/joshday/.julia/v0.5/OnlineStats/src/streamstats/bootstrap.jl:76\nPoissonBootstrap{T\n:OnlineStats.VectorInput}(o::OnlineStats.OnlineStat{T}, f::Function, r::Int64) at /Users/joshday/.julia/v0.5/OnlineStats/src/streamstats/bootstrap.jl:76\n\n\n\n\n\nQuantileMM\n\n\nApproximate quantiles via an online MM algorithm.  Typically more accurate than \nQuantileSGD\n.\n\n\no\n \n=\n \nQuantileMM\n(\ny\n,\n \nLearningRate\n())\n\n\no\n \n=\n \nQuantileMM\n(\ny\n,\n \ntau\n \n=\n \n[\n.\n25\n,\n \n.\n5\n,\n \n.\n75\n])\n\n\nfit!\n(\no\n,\n \ny2\n)\n\n\n\n\n\n\nQuantileSGD\n\n\nApproximate quantiles via stochastic gradient descent.\n\n\no\n \n=\n \nQuantileSGD\n(\ny\n,\n \nLearningRate\n())\n\n\no\n \n=\n \nQuantileSGD\n(\ny\n,\n \ntau\n \n=\n \n[\n.\n25\n,\n \n.\n5\n,\n \n.\n75\n])\n\n\nfit!\n(\no\n,\n \ny2\n)\n\n\n\n\n\n\nScalarInput\n\n\nNo documentation found.\n\n\nSummary:\n\n\nabstract OnlineStats.ScalarInput \n: OnlineStats.Input\n\n\n\n\n\nSum\n\n\nTrack the running sum.  Ignores \nWeight\n.\n\n\no\n \n=\n \nSum\n()\n\n\no\n \n=\n \nSum\n(\ny\n)\n\n\n\n\n\n\nSums\n\n\nTrack the running sum for multiple series.  Ignores \nWeight\n.\n\n\no\n \n=\n \nSums\n()\n\n\no\n \n=\n \nSums\n(\ny\n)\n\n\n\n\n\n\nTwoWayInteractionMatrix\n\n\nAdd second-order interaction terms on the fly without creating or copying data:\n\n\n\n\nTwoWayInteractionMatrix(rand(n, p))\n \"adds\" the \nbinomial(p, 2)\n interaction terms\n\n\n\n\nto each row\n\n\nTwoWayInteractionVector\n\n\nAdd second-order interaction terms on the fly without creating or copying data:\n\n\n\n\nTwoWayInteractionVector(rand(p))\n \"adds\" the \nbinomial(p, 2)\n interaction terms\n\n\n\n\nVariance\n\n\nUnivariate variance.\n\n\ny\n \n=\n \nrandn\n(\n100\n)\n\n\no\n \n=\n \nVariance\n(\ny\n)\n\n\nmean\n(\no\n)\n\n\nvar\n(\no\n)\n\n\nstd\n(\no\n)\n\n\n\n\n\n\nVariances\n\n\nVariances of a multiple series, similar to \nvar(x, 1)\n.\n\n\no\n \n=\n \nVariances\n(\nx\n,\n \nEqualWeight\n())\n\n\no\n \n=\n \nVariances\n(\nx\n)\n\n\nfit!\n(\no\n,\n \nx2\n)\n\n\n\nmean\n(\no\n)\n\n\nvar\n(\no\n)\n\n\nstd\n(\no\n)\n\n\n\n\n\n\nVectorInput\n\n\nNo documentation found.\n\n\nSummary:\n\n\nabstract OnlineStats.VectorInput \n: OnlineStats.Input\n\n\n\n\n\nWeight\n\n\nNo documentation found.\n\n\nSummary:\n\n\nabstract OnlineStats.Weight \n: Any\n\n\n\n\n\nSubtypes:\n\n\nOnlineStats.BatchWeight\nOnlineStats.BoundedEqualWeight\nOnlineStats.ExponentialWeight\n\n\n\n\n\nXYInput\n\n\nNo documentation found.\n\n\nSummary:\n\n\nabstract OnlineStats.XYInput \n: OnlineStats.Input\n\n\n\n\n\ncached_state\n\n\nNo documentation found.\n\n\nOnlineStats.cached_state\n is a \nFunction\n.\n\n\n# 3 methods for generic function \ncached_state\n:\ncached_state(b::OnlineStats.FrozenBootstrap) at /Users/joshday/.julia/v0.5/OnlineStats/src/streamstats/bootstrap.jl:103\ncached_state(b::OnlineStats.Bootstrap{OnlineStats.ScalarInput}) at /Users/joshday/.julia/v0.5/OnlineStats/src/streamstats/bootstrap.jl:116\ncached_state(b::OnlineStats.Bootstrap{OnlineStats.VectorInput}) at /Users/joshday/.julia/v0.5/OnlineStats/src/streamstats/bootstrap.jl:125\n\n\n\n\n\ncenter\n\n\nNo documentation found.\n\n\nOnlineStats.center\n is a \nFunction\n.\n\n\n# 4 methods for generic function \ncenter\n:\ncenter(o::OnlineStats.Mean, x::Real) at /Users/joshday/.julia/v0.5/OnlineStats/src/summary.jl:24\ncenter{T\n:Real}(o::OnlineStats.Means, x::AbstractArray{T,1}) at /Users/joshday/.julia/v0.5/OnlineStats/src/summary.jl:49\ncenter(o::OnlineStats.Variance, x::Real) at /Users/joshday/.julia/v0.5/OnlineStats/src/summary.jl:80\ncenter{T\n:Real}(o::OnlineStats.Variances, x::AbstractArray{T,1}) at /Users/joshday/.julia/v0.5/OnlineStats/src/summary.jl:126\n\n\n\n\n\nfit\n\n\nNo documentation found.\n\n\nStatsBase.fit\n is a \nFunction\n.\n\n\n#\n \n17\n \nmethods\n \nfor\n \ngeneric\n \nfunction\n \nfit\n:\n\n\nfit\n(:\n:Type\n{\nStatsBase\n.\nHistogram\n}\n,\n \nv\n:\n:AbstractArray\n{\nT\n:\nAny\n,\n1\n}\n;\n \nclosed\n,\n \nnbins\n)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nStatsBase\n/\nsrc\n/\nhist\n.jl\n:165\n\n\nfit\n(:\n:Type\n{\nStatsBase\n.\nHistogram\n}\n,\n \nv\n:\n:AbstractArray\n{\nT\n:\nAny\n,\n1\n}\n,\n \nedg\n:\n:AbstractArray\n{\nT\n:\nAny\n,\n1\n}\n;\n \nclosed\n)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nStatsBase\n/\nsrc\n/\nhist\n.jl\n:163\n\n\nfit\n(:\n:Type\n{\nStatsBase\n.\nHistogram\n}\n,\n \nv\n:\n:AbstractArray\n{\nT\n:\nAny\n,\n1\n}\n,\n \nwv\n:\n:StatsBase\n.WeightVec\n;\n \nclosed\n,\n \nnbins\n)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nStatsBase\n/\nsrc\n/\nhist\n.jl\n:170\n\n\nfit\n{\nW\n}\n(:\n:Type\n{\nStatsBase\n.\nHistogram\n}\n,\n \nv\n:\n:AbstractArray\n{\nT\n:\nAny\n,\n1\n}\n,\n \nwv\n:\n:StatsBase\n.WeightVec\n{\nW\n,\nVec\n:\nAbstractArray\n{\nT\n:\nReal\n,\n1\n}\n}\n,\n \nedg\n:\n:AbstractArray\n{\nT\n:\nAny\n,\n1\n}\n;\n \nclosed\n)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nStatsBase\n/\nsrc\n/\nhist\n.jl\n:168\n\n\nfit\n{\nN\n}\n(:\n:Type\n{\nStatsBase\n.\nHistogram\n}\n,\n \nvs\n:\n:Tuple\n{\nVararg\n{\nAbstractArray\n{\nT\n:\nAny\n,\n1\n}\n,\nN\n}}\n,\n \nedges\n:\n:Tuple\n{\nVararg\n{\nAbstractArray\n{\nT\n:\nAny\n,\n1\n}\n,\nN\n}}\n;\n \nclosed\n)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nStatsBase\n/\nsrc\n/\nhist\n.jl\n:202\n\n\nfit\n{\nN\n}\n(:\n:Type\n{\nStatsBase\n.\nHistogram\n}\n,\n \nvs\n:\n:Tuple\n{\nVararg\n{\nAbstractArray\n{\nT\n:\nAny\n,\n1\n}\n,\nN\n}}\n;\n \nclosed\n,\n \nnbins\n)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nStatsBase\n/\nsrc\n/\nhist\n.jl\n:204\n\n\nfit\n{\nN\n}\n(:\n:Type\n{\nStatsBase\n.\nHistogram\n}\n,\n \nvs\n:\n:Tuple\n{\nVararg\n{\nAbstractArray\n{\nT\n:\nAny\n,\n1\n}\n,\nN\n}}\n,\n \nwv\n:\n:StatsBase\n.WeightVec\n;\n \nclosed\n,\n \nnbins\n)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nStatsBase\n/\nsrc\n/\nhist\n.jl\n:209\n\n\nfit\n{\nN\n,\nW\n}\n(:\n:Type\n{\nStatsBase\n.\nHistogram\n}\n,\n \nvs\n:\n:Tuple\n{\nVararg\n{\nAbstractArray\n{\nT\n:\nAny\n,\n1\n}\n,\nN\n}}\n,\n \nwv\n:\n:StatsBase\n.WeightVec\n{\nW\n,\nVec\n:\nAbstractArray\n{\nT\n:\nReal\n,\n1\n}\n}\n,\n \nedges\n:\n:Tuple\n{\nVararg\n{\nAbstractArray\n{\nT\n:\nAny\n,\n1\n}\n,\nN\n}}\n;\n \nclosed\n)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nStatsBase\n/\nsrc\n/\nhist\n.jl\n:207\n\n\nfit\n(\nobj\n:\n:StatsBase\n.StatisticalModel\n,\n \ndata\n...)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nStatsBase\n/\nsrc\n/\nstatmodels\n.jl\n:46\n\n\nfit\n(:\n:Type\n{\nDistributions\n.\nBinomial\n}\n,\n \ndata\n:\n:Tuple\n{\nInt64\n,\nAbstractArray\n}\n)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nDistributions\n/\nsrc\n/\nunivariate\n/\ndiscrete\n/\nbinomial\n.jl\n:206\n\n\nfit\n(:\n:Type\n{\nDistributions\n.\nBinomial\n}\n,\n \ndata\n:\n:Tuple\n{\nInt64\n,\nAbstractArray\n}\n,\n \nw\n:\n:AbstractArray\n{\nFloat64\n,\nN\n:\nAny\n}\n)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nDistributions\n/\nsrc\n/\nunivariate\n/\ndiscrete\n/\nbinomial\n.jl\n:207\n\n\nfit\n(:\n:Type\n{\nDistributions\n.\nCategorical\n}\n,\n \ndata\n:\n:Tuple\n{\nInt64\n,\nAbstractArray\n}\n)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nDistributions\n/\nsrc\n/\nunivariate\n/\ndiscrete\n/\ncategorical\n.jl\n:273\n\n\nfit\n(:\n:Type\n{\nDistributions\n.\nCategorical\n}\n,\n \ndata\n:\n:Tuple\n{\nInt64\n,\nAbstractArray\n}\n,\n \nw\n:\n:AbstractArray\n{\nFloat64\n,\nN\n:\nAny\n}\n)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nDistributions\n/\nsrc\n/\nunivariate\n/\ndiscrete\n/\ncategorical\n.jl\n:274\n\n\nfit\n{\nT\n:\nReal\n}\n(:\n:Type\n{\nDistributions\n.\nBeta\n}\n,\n \nx\n:\n:AbstractArray\n{\nT\n,\nN\n:\nAny\n}\n)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nDistributions\n/\nsrc\n/\nunivariate\n/\ncontinuous\n/\nbeta\n.jl\n:128\n\n\nfit\n{\nT\n:\nReal\n}\n(:\n:Type\n{\nDistributions\n.\nCauchy\n}\n,\n \nx\n:\n:AbstractArray\n{\nT\n,\nN\n:\nAny\n}\n)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nDistributions\n/\nsrc\n/\nunivariate\n/\ncontinuous\n/\ncauchy\n.jl\n:108\n\n\nfit\n{\nD\n:\nDistributions\n.\nDistribution\n{\nF\n:\nDistributions\n.\nVariateForm\n,\nS\n:\nDistributions\n.\nValueSupport\n}\n}\n(\ndt\n:\n:Type\n{\nD\n}\n,\n \nx\n)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nDistributions\n/\nsrc\n/\ngenericfit\n.jl\n:14\n\n\nfit\n{\nD\n:\nDistributions\n.\nDistribution\n{\nF\n:\nDistributions\n.\nVariateForm\n,\nS\n:\nDistributions\n.\nValueSupport\n}\n}\n(\ndt\n:\n:Type\n{\nD\n}\n,\n \nargs\n...)\n \nat\n \n/\nUsers\n/\njoshday\n/\n.julia\n/\nv0\n.5\n/\nDistributions\n/\nsrc\n/\ngenericfit\n.jl\n:15\n\n\n\n\n\n\nfit!\n\n\nUpdate an OnlineStat with more data.  Additional arguments after the input data provide extra control over how the updates are done.\n\n\ny = randn(100)\no = Mean()\n\nfit!(o, y)      # standard usage\n\nfit!(o, y, 10)  # update in minibatches of size 10\n\nfit!(o, y, .1)  # update using weight .1 for each observation\n\nwts = rand(100)\nfit!(o, y, wts) # update observation i using wts[i]\n\n\n\n\n\nUpdate an OnlineStat with more data.  Additional arguments after the input data provide extra control over how the updates are done.\n\n\ny = randn(100)\no = Mean()\n\nfit!(o, y)      # standard usage\n\nfit!(o, y, 10)  # update in minibatches of size 10\n\nfit!(o, y, .1)  # update using weight .1 for each observation\n\nwts = rand(100)\nfit!(o, y, wts) # update observation i using wts[i]\n\n\n\n\n\nUpdate an OnlineStat with more data.  Additional arguments after the input data provide extra control over how the updates are done.\n\n\ny = randn(100)\no = Mean()\n\nfit!(o, y)      # standard usage\n\nfit!(o, y, 10)  # update in minibatches of size 10\n\nfit!(o, y, .1)  # update using weight .1 for each observation\n\nwts = rand(100)\nfit!(o, y, wts) # update observation i using wts[i]\n\n\n\n\n\nUpdate an OnlineStat with more data.  Additional arguments after the input data provide extra control over how the updates are done.\n\n\ny = randn(100)\no = Mean()\n\nfit!(o, y)      # standard usage\n\nfit!(o, y, 10)  # update in minibatches of size 10\n\nfit!(o, y, .1)  # update using weight .1 for each observation\n\nwts = rand(100)\nfit!(o, y, wts) # update observation i using wts[i]\n\n\n\n\n\nUpdate an OnlineStat with more data.  Additional arguments after the input data provide extra control over how the updates are done.\n\n\ny = randn(100)\no = Mean()\n\nfit!(o, y)      # standard usage\n\nfit!(o, y, 10)  # update in minibatches of size 10\n\nfit!(o, y, .1)  # update using weight .1 for each observation\n\nwts = rand(100)\nfit!(o, y, wts) # update observation i using wts[i]\n\n\n\n\n\nfitdistribution\n\n\nEstimate the parameters of a distribution.\n\n\nusing\n \nDistributions\n\n\n# Univariate distributions\n\n\no\n \n=\n \nfitdistribution\n(\nBeta\n,\n \ny\n)\n\n\no\n \n=\n \nfitdistribution\n(\nCategorical\n,\n \ny\n)\n  \n# ignores Weight\n\n\no\n \n=\n \nfitdistribution\n(\nCauchy\n,\n \ny\n)\n\n\no\n \n=\n \nfitdistribution\n(\nGamma\n,\n \ny\n)\n\n\no\n \n=\n \nfitdistribution\n(\nLogNormal\n,\n \ny\n)\n\n\no\n \n=\n \nfitdistribution\n(\nNormal\n,\n \ny\n)\n\n\nmean\n(\no\n)\n\n\nvar\n(\no\n)\n\n\nstd\n(\no\n)\n\n\nparams\n(\no\n)\n\n\n\n# Multivariate distributions\n\n\no\n \n=\n \nfitdistribution\n(\nMultinomial\n,\n \nx\n)\n\n\no\n \n=\n \nfitdistribution\n(\nMvNormal\n,\n \nx\n)\n\n\nmean\n(\no\n)\n\n\nvar\n(\no\n)\n\n\nstd\n(\no\n)\n\n\ncov\n(\no\n)\n\n\n\n\n\n\nkurtosis\n\n\nkurtosis(v, [wv::WeightVec], m=mean(v))\n\n\n\n\n\nCompute the excess kurtosis of a real-valued array \nv\n, optionally specifying a weighting vector \nwv\n and a center \nm\n.\n\n\nmaprows\n\n\nPerform operations on data in blocks.\n\n\nmaprows(f::Function, b::Integer, data...)\n\n\nThis function iteratively feeds \ndata\n in blocks of \nb\n observations to the function \nf\n.  The most common usage is with \ndo\n blocks:\n\n\n# Example 1\n\n\ny\n \n=\n \nrandn\n(\n50\n)\n\n\no\n \n=\n \nVariance\n()\n\n\nmaprows\n(\n10\n,\n \ny\n)\n \ndo\n \nyi\n\n    \nfit!\n(\no\n,\n \nyi\n)\n\n    \nprintln\n(\nUpdated with another batch!\n)\n\n\nend\n\n\n\n\n\n\nnobs\n\n\nnobs(obj::StatisticalModel)\n\n\n\n\n\nReturns the number of independent observations on which the model was fitted. Be careful when using this information, as the definition of an independent observation may vary depending on the model, on the format used to pass the data, on the sampling plan (if specified), etc.\n\n\nreplicates\n\n\nNo documentation found.\n\n\nOnlineStats.replicates\n is a \nFunction\n.\n\n\n# 1 method for generic function \nreplicates\n:\nreplicates(b::OnlineStats.Bootstrap) at /Users/joshday/.julia/v0.5/OnlineStats/src/streamstats/bootstrap.jl:143\n\n\n\n\n\nskewness\n\n\nskewness(v, [wv::WeightVec], m=mean(v))\n\n\n\n\n\nCompute the standardized skewness of a real-valued array \nv\n, optionally specifying a weighting vector \nwv\n and a center \nm\n.\n\n\nvalue\n\n\nThe associated value of an OnlineStat.\n\n\no = Mean()\nvalue(o)\n\n\n\n\n\nvalue(loss::SupervisedLoss, target::AbstractArray, output::AbstractArray)\n\n\n\n\n\nComputes the value of the loss function for each observation-pair in targets and outputs individual and returns the result as an array of the same size as the parameters.\n\n\nThe associated value of an OnlineStat.\n\n\no = Mean()\nvalue(o)\n\n\n\n\n\nThe associated value of an OnlineStat.\n\n\no = Mean()\nvalue(o)\n\n\n\n\n\nThe associated value of an OnlineStat.\n\n\no = Mean()\nvalue(o)\n\n\n\n\n\nThe associated value of an OnlineStat.\n\n\no = Mean()\nvalue(o)", 
            "title": "API/Examples"
        }, 
        {
            "location": "/api/#api", 
            "text": "", 
            "title": "API"
        }, 
        {
            "location": "/api/#bernoullibootstrap", 
            "text": "BernoulliBootstrap(o::OnlineStat, f::Function, r::Int = 1000)  Create a double-or-nothing bootstrap using  r  replicates of  o  for estimate  f(o)  Example:  BernoulliBootstrap ( Mean (),   mean ,   1000 )", 
            "title": "BernoulliBootstrap"
        }, 
        {
            "location": "/api/#biasmatrix", 
            "text": "Adda bias/intercept term to a matrix on the fly without creating or copying data:   BiasMatrix(rand(10,5))  is roughly equivalent to  hcat(rand(10,5), ones(10))", 
            "title": "BiasMatrix"
        }, 
        {
            "location": "/api/#biasvector", 
            "text": "Add a bias/intercept term to a vector on the fly without creating or copying data:   BiasVector(rand(10))  is roughly equivalent to  vcat(rand(10), 1.0)", 
            "title": "BiasVector"
        }, 
        {
            "location": "/api/#boundedequalweight", 
            "text": "One of the  Weight  types.  Uses  EqualWeight  until reaching  \u03bb = 2 / (1 + lookback) , then weights are held constant.   BoundedEqualWeight(\u03bb::Float64)  BoundedEqualWeight(lookback::Int)", 
            "title": "BoundedEqualWeight"
        }, 
        {
            "location": "/api/#covmatrix", 
            "text": "Covariance matrix, similar to  cov(x) .  o   =   CovMatrix ( x ,   EqualWeight ())  o   =   CovMatrix ( x )  fit! ( o ,   x2 )  cor ( o )  cov ( o )  mean ( o )  var ( o )", 
            "title": "CovMatrix"
        }, 
        {
            "location": "/api/#diff", 
            "text": "Track the last value and the last difference.  o   =   Diff ()  o   =   Diff ( y )", 
            "title": "Diff"
        }, 
        {
            "location": "/api/#diffs", 
            "text": "Track the last value and the last difference for multiple series.  Ignores  Weight .  o   =   Diffs ()  o   =   Diffs ( y )", 
            "title": "Diffs"
        }, 
        {
            "location": "/api/#equalweight", 
            "text": "One of the  Weight  types.  Observations are weighted equally.  For analytical updates, the online algorithm will give results equal to the offline version.   EqualWeight()", 
            "title": "EqualWeight"
        }, 
        {
            "location": "/api/#exponentialweight", 
            "text": "One of the  Weight  types.  Updates are performed with a constant weight  \u03bb = 2 / (1 + lookback) .   ExponentialWeight(\u03bb::Float64)  ExponentialWeight(lookback::Int)", 
            "title": "ExponentialWeight"
        }, 
        {
            "location": "/api/#extrema", 
            "text": "Extrema (maximum and minimum).  o   =   Extrema ( y )  fit! ( o ,   y2 )  extrema ( o )", 
            "title": "Extrema"
        }, 
        {
            "location": "/api/#fitbeta", 
            "text": "No documentation found.  Summary:  type OnlineStats.FitBeta{W :OnlineStats.Weight}  : OnlineStats.DistributionStat{OnlineStats.ScalarInput}  Fields:  value :: Distributions.Beta{T :Real}\nvar   :: OnlineStats.Variance{W :OnlineStats.Weight}", 
            "title": "FitBeta"
        }, 
        {
            "location": "/api/#fitcategorical", 
            "text": "Find the proportions for each unique input.  Categories are sorted by proportions. Ignores  Weight .  o   =   FitCategorical ( y )", 
            "title": "FitCategorical"
        }, 
        {
            "location": "/api/#fitcauchy", 
            "text": "No documentation found.  Summary:  type OnlineStats.FitCauchy{W :OnlineStats.Weight}  : OnlineStats.DistributionStat{OnlineStats.ScalarInput}  Fields:  value :: Distributions.Cauchy{T :Real}\nq     :: OnlineStats.QuantileMM{W :OnlineStats.Weight}", 
            "title": "FitCauchy"
        }, 
        {
            "location": "/api/#fitgamma", 
            "text": "No documentation found.  Summary:  type OnlineStats.FitGamma{W :OnlineStats.Weight}  : OnlineStats.DistributionStat{OnlineStats.ScalarInput}  Fields:  value :: Distributions.Gamma{T :Real}\nvar   :: OnlineStats.Variance{W :OnlineStats.Weight}", 
            "title": "FitGamma"
        }, 
        {
            "location": "/api/#fitlognormal", 
            "text": "No documentation found.  Summary:  type OnlineStats.FitLogNormal{W :OnlineStats.Weight}  : OnlineStats.DistributionStat{OnlineStats.ScalarInput}  Fields:  value :: Distributions.LogNormal{T :Real}\nvar   :: OnlineStats.Variance{W :OnlineStats.Weight}", 
            "title": "FitLogNormal"
        }, 
        {
            "location": "/api/#fitmultinomial", 
            "text": "No documentation found.  Summary:  type OnlineStats.FitMultinomial{W :OnlineStats.Weight}  : OnlineStats.DistributionStat{OnlineStats.VectorInput}  Fields:  value :: Distributions.Multinomial{T :Real}\nmeans :: OnlineStats.Means{W :OnlineStats.Weight}", 
            "title": "FitMultinomial"
        }, 
        {
            "location": "/api/#fitmvnormal", 
            "text": "No documentation found.  Summary:  type OnlineStats.FitMvNormal{W :OnlineStats.Weight}  : OnlineStats.DistributionStat{OnlineStats.VectorInput}  Fields:  value :: Distributions.MvNormal{T :Real,Cov :PDMats.AbstractPDMat,Mean :Union{Array{T,1},Distributions.ZeroVector}}\ncov   :: OnlineStats.CovMatrix{W :OnlineStats.Weight}", 
            "title": "FitMvNormal"
        }, 
        {
            "location": "/api/#fitnormal", 
            "text": "No documentation found.  Summary:  type OnlineStats.FitNormal{W :OnlineStats.Weight}  : OnlineStats.DistributionStat{OnlineStats.ScalarInput}  Fields:  value :: Distributions.Normal{T :Real}\nvar   :: OnlineStats.Variance{W :OnlineStats.Weight}", 
            "title": "FitNormal"
        }, 
        {
            "location": "/api/#frozenbootstrap", 
            "text": "No documentation found.  Summary:  immutable OnlineStats.FrozenBootstrap  : OnlineStats.Bootstrap{OnlineStats.ScalarInput}  Fields:  cached_state :: Array{Float64,1}\nn            :: Int64", 
            "title": "FrozenBootstrap"
        }, 
        {
            "location": "/api/#hyperloglog", 
            "text": "HyperLogLog(b)  Approximate count of distinct elements.   HyperLogLog  differs from other OnlineStats in that any input to  fit!(o::HyperLogLog, input)  is considered a singleton.  Thus, a vector of inputs must be done by:  o   =   HyperLogLog ( 4 )  for   yi   in   y \n     fit! ( o ,   yi )  end", 
            "title": "HyperLogLog"
        }, 
        {
            "location": "/api/#kmeans", 
            "text": "Approximate K-Means clustering of multivariate data.  o   =   KMeans ( y ,   3 ,   LearningRate ())  value ( o )", 
            "title": "KMeans"
        }, 
        {
            "location": "/api/#learningrate", 
            "text": "One of the  Weight  types.  It's primary use is for the OnlineStats that use stochastic approximation ( StatLearn ,  QuantReg ,  QuantileMM ,  QuantileSGD ,  NormalMix , and  KMeans ).  The weight at update  t  is  1 / t ^ r .  When weights reach  \u03bb , they are held consant.  Compare to  LearningRate2 .   LearningRate(r = 0.5, \u03bb = 0.0)", 
            "title": "LearningRate"
        }, 
        {
            "location": "/api/#learningrate2", 
            "text": "One of the  Weight  types.  It's primary use is for the OnlineStats that use stochastic approximation ( StatLearn ,  QuantReg ,  QuantileMM ,  QuantileSGD ,  NormalMix , and  KMeans ).  The weight at update  t  is  1 / (1 + c * (t - 1)) .  When weights reach  \u03bb , they are held consant.  Compare to  LearningRate .   LearningRate2(c = 0.5, \u03bb = 0.0)", 
            "title": "LearningRate2"
        }, 
        {
            "location": "/api/#mean", 
            "text": "Mean of a single series.  y   =   randn ( 100 )  o   =   Mean ()  fit! ( o ,   y )  o   =   Mean ( y )", 
            "title": "Mean"
        }, 
        {
            "location": "/api/#means", 
            "text": "Means of multiple series, similar to  mean(x, 1) .  x   =   randn ( 1000 ,   5 )  o   =   Means ( 5 )  fit! ( o ,   x )  mean ( o )", 
            "title": "Means"
        }, 
        {
            "location": "/api/#moments", 
            "text": "Univariate, first four moments.  Provides  mean ,  var ,  skewness ,  kurtosis  o   =   Moments ( x ,   EqualWeight ())  o   =   Moments ( x )  fit! ( o ,   x2 )  mean ( o )  var ( o )  std ( o )  StatsBase . skewness ( o )  StatsBase . kurtosis ( o )", 
            "title": "Moments"
        }, 
        {
            "location": "/api/#normalmix", 
            "text": "Normal Mixture of  k  components via an online EM algorithm.   start  is a keyword argument specifying the initial parameters.  o   =   NormalMix ( 2 ,   LearningRate ();   start   =   MixtureModel ( Normal ,   [( 0 ,   1 ),   ( 3 ,   1 )]))  mean ( o )  var ( o )  std ( o )", 
            "title": "NormalMix"
        }, 
        {
            "location": "/api/#onlinestat", 
            "text": "No documentation found.  Summary:  abstract OnlineStats.OnlineStat{I :OnlineStats.Input}  : Any  Subtypes:  OnlineStats.Bootstrap{I :OnlineStats.Input}\nOnlineStats.CovMatrix{W :OnlineStats.Weight}\nOnlineStats.Diffs{T :Real}\nOnlineStats.Diff{T :Real}\nOnlineStats.DistributionStat{I :OnlineStats.Input}\nOnlineStats.Extrema\nOnlineStats.HyperLogLog\nOnlineStats.KMeans{W :OnlineStats.Weight}\nOnlineStats.Means{W :OnlineStats.Weight}\nOnlineStats.Mean{W :OnlineStats.Weight}\nOnlineStats.Moments{W :OnlineStats.Weight}\nOnlineStats.OrderStatistics\nOnlineStats.QuantileMM{W :OnlineStats.Weight}\nOnlineStats.QuantileSGD{W :OnlineStats.StochasticWeight}\nOnlineStats.Sums{T :Real}\nOnlineStats.Sum{T :Real}\nOnlineStats.Variances{W :OnlineStats.Weight}\nOnlineStats.Variance{W :OnlineStats.Weight}", 
            "title": "OnlineStat"
        }, 
        {
            "location": "/api/#poissonbootstrap", 
            "text": "No documentation found.  OnlineStats.PoissonBootstrap  is a  Function .  # 4 methods for generic function  PoissonBootstrap :\nPoissonBootstrap{T :OnlineStats.ScalarInput}(o::OnlineStats.OnlineStat{T}, f::Function) at /Users/joshday/.julia/v0.5/OnlineStats/src/streamstats/bootstrap.jl:63\nPoissonBootstrap{T :OnlineStats.ScalarInput}(o::OnlineStats.OnlineStat{T}, f::Function, r::Int64) at /Users/joshday/.julia/v0.5/OnlineStats/src/streamstats/bootstrap.jl:63\nPoissonBootstrap{T :OnlineStats.VectorInput}(o::OnlineStats.OnlineStat{T}, f::Function) at /Users/joshday/.julia/v0.5/OnlineStats/src/streamstats/bootstrap.jl:76\nPoissonBootstrap{T :OnlineStats.VectorInput}(o::OnlineStats.OnlineStat{T}, f::Function, r::Int64) at /Users/joshday/.julia/v0.5/OnlineStats/src/streamstats/bootstrap.jl:76", 
            "title": "PoissonBootstrap"
        }, 
        {
            "location": "/api/#quantilemm", 
            "text": "Approximate quantiles via an online MM algorithm.  Typically more accurate than  QuantileSGD .  o   =   QuantileMM ( y ,   LearningRate ())  o   =   QuantileMM ( y ,   tau   =   [ . 25 ,   . 5 ,   . 75 ])  fit! ( o ,   y2 )", 
            "title": "QuantileMM"
        }, 
        {
            "location": "/api/#quantilesgd", 
            "text": "Approximate quantiles via stochastic gradient descent.  o   =   QuantileSGD ( y ,   LearningRate ())  o   =   QuantileSGD ( y ,   tau   =   [ . 25 ,   . 5 ,   . 75 ])  fit! ( o ,   y2 )", 
            "title": "QuantileSGD"
        }, 
        {
            "location": "/api/#scalarinput", 
            "text": "No documentation found.  Summary:  abstract OnlineStats.ScalarInput  : OnlineStats.Input", 
            "title": "ScalarInput"
        }, 
        {
            "location": "/api/#sum", 
            "text": "Track the running sum.  Ignores  Weight .  o   =   Sum ()  o   =   Sum ( y )", 
            "title": "Sum"
        }, 
        {
            "location": "/api/#sums", 
            "text": "Track the running sum for multiple series.  Ignores  Weight .  o   =   Sums ()  o   =   Sums ( y )", 
            "title": "Sums"
        }, 
        {
            "location": "/api/#twowayinteractionmatrix", 
            "text": "Add second-order interaction terms on the fly without creating or copying data:   TwoWayInteractionMatrix(rand(n, p))  \"adds\" the  binomial(p, 2)  interaction terms   to each row", 
            "title": "TwoWayInteractionMatrix"
        }, 
        {
            "location": "/api/#twowayinteractionvector", 
            "text": "Add second-order interaction terms on the fly without creating or copying data:   TwoWayInteractionVector(rand(p))  \"adds\" the  binomial(p, 2)  interaction terms", 
            "title": "TwoWayInteractionVector"
        }, 
        {
            "location": "/api/#variance", 
            "text": "Univariate variance.  y   =   randn ( 100 )  o   =   Variance ( y )  mean ( o )  var ( o )  std ( o )", 
            "title": "Variance"
        }, 
        {
            "location": "/api/#variances", 
            "text": "Variances of a multiple series, similar to  var(x, 1) .  o   =   Variances ( x ,   EqualWeight ())  o   =   Variances ( x )  fit! ( o ,   x2 )  mean ( o )  var ( o )  std ( o )", 
            "title": "Variances"
        }, 
        {
            "location": "/api/#vectorinput", 
            "text": "No documentation found.  Summary:  abstract OnlineStats.VectorInput  : OnlineStats.Input", 
            "title": "VectorInput"
        }, 
        {
            "location": "/api/#weight", 
            "text": "No documentation found.  Summary:  abstract OnlineStats.Weight  : Any  Subtypes:  OnlineStats.BatchWeight\nOnlineStats.BoundedEqualWeight\nOnlineStats.ExponentialWeight", 
            "title": "Weight"
        }, 
        {
            "location": "/api/#xyinput", 
            "text": "No documentation found.  Summary:  abstract OnlineStats.XYInput  : OnlineStats.Input", 
            "title": "XYInput"
        }, 
        {
            "location": "/api/#cached_state", 
            "text": "No documentation found.  OnlineStats.cached_state  is a  Function .  # 3 methods for generic function  cached_state :\ncached_state(b::OnlineStats.FrozenBootstrap) at /Users/joshday/.julia/v0.5/OnlineStats/src/streamstats/bootstrap.jl:103\ncached_state(b::OnlineStats.Bootstrap{OnlineStats.ScalarInput}) at /Users/joshday/.julia/v0.5/OnlineStats/src/streamstats/bootstrap.jl:116\ncached_state(b::OnlineStats.Bootstrap{OnlineStats.VectorInput}) at /Users/joshday/.julia/v0.5/OnlineStats/src/streamstats/bootstrap.jl:125", 
            "title": "cached_state"
        }, 
        {
            "location": "/api/#center", 
            "text": "No documentation found.  OnlineStats.center  is a  Function .  # 4 methods for generic function  center :\ncenter(o::OnlineStats.Mean, x::Real) at /Users/joshday/.julia/v0.5/OnlineStats/src/summary.jl:24\ncenter{T :Real}(o::OnlineStats.Means, x::AbstractArray{T,1}) at /Users/joshday/.julia/v0.5/OnlineStats/src/summary.jl:49\ncenter(o::OnlineStats.Variance, x::Real) at /Users/joshday/.julia/v0.5/OnlineStats/src/summary.jl:80\ncenter{T :Real}(o::OnlineStats.Variances, x::AbstractArray{T,1}) at /Users/joshday/.julia/v0.5/OnlineStats/src/summary.jl:126", 
            "title": "center"
        }, 
        {
            "location": "/api/#fit", 
            "text": "No documentation found.  StatsBase.fit  is a  Function .  #   17   methods   for   generic   function   fit :  fit (: :Type { StatsBase . Histogram } ,   v : :AbstractArray { T : Any , 1 } ;   closed ,   nbins )   at   / Users / joshday / .julia / v0 .5 / StatsBase / src / hist .jl :165  fit (: :Type { StatsBase . Histogram } ,   v : :AbstractArray { T : Any , 1 } ,   edg : :AbstractArray { T : Any , 1 } ;   closed )   at   / Users / joshday / .julia / v0 .5 / StatsBase / src / hist .jl :163  fit (: :Type { StatsBase . Histogram } ,   v : :AbstractArray { T : Any , 1 } ,   wv : :StatsBase .WeightVec ;   closed ,   nbins )   at   / Users / joshday / .julia / v0 .5 / StatsBase / src / hist .jl :170  fit { W } (: :Type { StatsBase . Histogram } ,   v : :AbstractArray { T : Any , 1 } ,   wv : :StatsBase .WeightVec { W , Vec : AbstractArray { T : Real , 1 } } ,   edg : :AbstractArray { T : Any , 1 } ;   closed )   at   / Users / joshday / .julia / v0 .5 / StatsBase / src / hist .jl :168  fit { N } (: :Type { StatsBase . Histogram } ,   vs : :Tuple { Vararg { AbstractArray { T : Any , 1 } , N }} ,   edges : :Tuple { Vararg { AbstractArray { T : Any , 1 } , N }} ;   closed )   at   / Users / joshday / .julia / v0 .5 / StatsBase / src / hist .jl :202  fit { N } (: :Type { StatsBase . Histogram } ,   vs : :Tuple { Vararg { AbstractArray { T : Any , 1 } , N }} ;   closed ,   nbins )   at   / Users / joshday / .julia / v0 .5 / StatsBase / src / hist .jl :204  fit { N } (: :Type { StatsBase . Histogram } ,   vs : :Tuple { Vararg { AbstractArray { T : Any , 1 } , N }} ,   wv : :StatsBase .WeightVec ;   closed ,   nbins )   at   / Users / joshday / .julia / v0 .5 / StatsBase / src / hist .jl :209  fit { N , W } (: :Type { StatsBase . Histogram } ,   vs : :Tuple { Vararg { AbstractArray { T : Any , 1 } , N }} ,   wv : :StatsBase .WeightVec { W , Vec : AbstractArray { T : Real , 1 } } ,   edges : :Tuple { Vararg { AbstractArray { T : Any , 1 } , N }} ;   closed )   at   / Users / joshday / .julia / v0 .5 / StatsBase / src / hist .jl :207  fit ( obj : :StatsBase .StatisticalModel ,   data ...)   at   / Users / joshday / .julia / v0 .5 / StatsBase / src / statmodels .jl :46  fit (: :Type { Distributions . Binomial } ,   data : :Tuple { Int64 , AbstractArray } )   at   / Users / joshday / .julia / v0 .5 / Distributions / src / univariate / discrete / binomial .jl :206  fit (: :Type { Distributions . Binomial } ,   data : :Tuple { Int64 , AbstractArray } ,   w : :AbstractArray { Float64 , N : Any } )   at   / Users / joshday / .julia / v0 .5 / Distributions / src / univariate / discrete / binomial .jl :207  fit (: :Type { Distributions . Categorical } ,   data : :Tuple { Int64 , AbstractArray } )   at   / Users / joshday / .julia / v0 .5 / Distributions / src / univariate / discrete / categorical .jl :273  fit (: :Type { Distributions . Categorical } ,   data : :Tuple { Int64 , AbstractArray } ,   w : :AbstractArray { Float64 , N : Any } )   at   / Users / joshday / .julia / v0 .5 / Distributions / src / univariate / discrete / categorical .jl :274  fit { T : Real } (: :Type { Distributions . Beta } ,   x : :AbstractArray { T , N : Any } )   at   / Users / joshday / .julia / v0 .5 / Distributions / src / univariate / continuous / beta .jl :128  fit { T : Real } (: :Type { Distributions . Cauchy } ,   x : :AbstractArray { T , N : Any } )   at   / Users / joshday / .julia / v0 .5 / Distributions / src / univariate / continuous / cauchy .jl :108  fit { D : Distributions . Distribution { F : Distributions . VariateForm , S : Distributions . ValueSupport } } ( dt : :Type { D } ,   x )   at   / Users / joshday / .julia / v0 .5 / Distributions / src / genericfit .jl :14  fit { D : Distributions . Distribution { F : Distributions . VariateForm , S : Distributions . ValueSupport } } ( dt : :Type { D } ,   args ...)   at   / Users / joshday / .julia / v0 .5 / Distributions / src / genericfit .jl :15", 
            "title": "fit"
        }, 
        {
            "location": "/api/#fit_1", 
            "text": "Update an OnlineStat with more data.  Additional arguments after the input data provide extra control over how the updates are done.  y = randn(100)\no = Mean()\n\nfit!(o, y)      # standard usage\n\nfit!(o, y, 10)  # update in minibatches of size 10\n\nfit!(o, y, .1)  # update using weight .1 for each observation\n\nwts = rand(100)\nfit!(o, y, wts) # update observation i using wts[i]  Update an OnlineStat with more data.  Additional arguments after the input data provide extra control over how the updates are done.  y = randn(100)\no = Mean()\n\nfit!(o, y)      # standard usage\n\nfit!(o, y, 10)  # update in minibatches of size 10\n\nfit!(o, y, .1)  # update using weight .1 for each observation\n\nwts = rand(100)\nfit!(o, y, wts) # update observation i using wts[i]  Update an OnlineStat with more data.  Additional arguments after the input data provide extra control over how the updates are done.  y = randn(100)\no = Mean()\n\nfit!(o, y)      # standard usage\n\nfit!(o, y, 10)  # update in minibatches of size 10\n\nfit!(o, y, .1)  # update using weight .1 for each observation\n\nwts = rand(100)\nfit!(o, y, wts) # update observation i using wts[i]  Update an OnlineStat with more data.  Additional arguments after the input data provide extra control over how the updates are done.  y = randn(100)\no = Mean()\n\nfit!(o, y)      # standard usage\n\nfit!(o, y, 10)  # update in minibatches of size 10\n\nfit!(o, y, .1)  # update using weight .1 for each observation\n\nwts = rand(100)\nfit!(o, y, wts) # update observation i using wts[i]  Update an OnlineStat with more data.  Additional arguments after the input data provide extra control over how the updates are done.  y = randn(100)\no = Mean()\n\nfit!(o, y)      # standard usage\n\nfit!(o, y, 10)  # update in minibatches of size 10\n\nfit!(o, y, .1)  # update using weight .1 for each observation\n\nwts = rand(100)\nfit!(o, y, wts) # update observation i using wts[i]", 
            "title": "fit!"
        }, 
        {
            "location": "/api/#fitdistribution", 
            "text": "Estimate the parameters of a distribution.  using   Distributions  # Univariate distributions  o   =   fitdistribution ( Beta ,   y )  o   =   fitdistribution ( Categorical ,   y )    # ignores Weight  o   =   fitdistribution ( Cauchy ,   y )  o   =   fitdistribution ( Gamma ,   y )  o   =   fitdistribution ( LogNormal ,   y )  o   =   fitdistribution ( Normal ,   y )  mean ( o )  var ( o )  std ( o )  params ( o )  # Multivariate distributions  o   =   fitdistribution ( Multinomial ,   x )  o   =   fitdistribution ( MvNormal ,   x )  mean ( o )  var ( o )  std ( o )  cov ( o )", 
            "title": "fitdistribution"
        }, 
        {
            "location": "/api/#kurtosis", 
            "text": "kurtosis(v, [wv::WeightVec], m=mean(v))  Compute the excess kurtosis of a real-valued array  v , optionally specifying a weighting vector  wv  and a center  m .", 
            "title": "kurtosis"
        }, 
        {
            "location": "/api/#maprows", 
            "text": "Perform operations on data in blocks.  maprows(f::Function, b::Integer, data...)  This function iteratively feeds  data  in blocks of  b  observations to the function  f .  The most common usage is with  do  blocks:  # Example 1  y   =   randn ( 50 )  o   =   Variance ()  maprows ( 10 ,   y )   do   yi \n     fit! ( o ,   yi ) \n     println ( Updated with another batch! )  end", 
            "title": "maprows"
        }, 
        {
            "location": "/api/#nobs", 
            "text": "nobs(obj::StatisticalModel)  Returns the number of independent observations on which the model was fitted. Be careful when using this information, as the definition of an independent observation may vary depending on the model, on the format used to pass the data, on the sampling plan (if specified), etc.", 
            "title": "nobs"
        }, 
        {
            "location": "/api/#replicates", 
            "text": "No documentation found.  OnlineStats.replicates  is a  Function .  # 1 method for generic function  replicates :\nreplicates(b::OnlineStats.Bootstrap) at /Users/joshday/.julia/v0.5/OnlineStats/src/streamstats/bootstrap.jl:143", 
            "title": "replicates"
        }, 
        {
            "location": "/api/#skewness", 
            "text": "skewness(v, [wv::WeightVec], m=mean(v))  Compute the standardized skewness of a real-valued array  v , optionally specifying a weighting vector  wv  and a center  m .", 
            "title": "skewness"
        }, 
        {
            "location": "/api/#value", 
            "text": "The associated value of an OnlineStat.  o = Mean()\nvalue(o)  value(loss::SupervisedLoss, target::AbstractArray, output::AbstractArray)  Computes the value of the loss function for each observation-pair in targets and outputs individual and returns the result as an array of the same size as the parameters.  The associated value of an OnlineStat.  o = Mean()\nvalue(o)  The associated value of an OnlineStat.  o = Mean()\nvalue(o)  The associated value of an OnlineStat.  o = Mean()\nvalue(o)  The associated value of an OnlineStat.  o = Mean()\nvalue(o)", 
            "title": "value"
        }
    ]
}